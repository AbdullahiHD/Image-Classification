{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set your dataset directory\n",
    "base_dir = \"dataset/train\"\n",
    "\n",
    "# The target number of files per class\n",
    "target_file_count = 1000\n",
    "\n",
    "# For each class directory in the train dataset\n",
    "for class_dir in os.listdir(base_dir):\n",
    "    class_path = os.path.join(base_dir, class_dir)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        # Get all file names\n",
    "        files = os.listdir(class_path)\n",
    "\n",
    "        # Shuffle the list in place and truncate files to the target count\n",
    "        random.shuffle(files)\n",
    "        files_to_keep = files[:target_file_count]\n",
    "\n",
    "        # Move the files to keep to a temporary directory\n",
    "        temp_dir = os.path.join(base_dir, \"temp_\" + class_dir)\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "        # Move files to keep into the temporary directory\n",
    "        for f in files_to_keep:\n",
    "            shutil.move(os.path.join(class_path, f), os.path.join(temp_dir, f))\n",
    "\n",
    "        # Remove the original directory\n",
    "        shutil.rmtree(class_path)\n",
    "\n",
    "        # Rename the temporary directory back to the original directory name\n",
    "        os.rename(temp_dir, class_path)\n",
    "\n",
    "print(\"Truncation complete. Each class now has a maximum of 1000 files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Validation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Set the base directory where train and test folders are located\n",
    "base_dir = \"dataset\"\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    \"happy\",\n",
    "    \"sad\",\n",
    "    \"angry\",\n",
    "    \"surprise\",\n",
    "]  # Add or modify according to your dataset\n",
    "\n",
    "# Desired splits: 70% for training, 15% for validation, 15% for testing\n",
    "train_split = 0.70\n",
    "validation_split = 0.15\n",
    "\n",
    "# Create validation directory\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "for label in class_labels:\n",
    "    # Create subdirectories for each class label in validation directory\n",
    "    os.makedirs(os.path.join(validation_dir, label), exist_ok=True)\n",
    "\n",
    "    # Source directory (train)\n",
    "    source_dir = os.path.join(base_dir, \"train\", label)\n",
    "\n",
    "    # Get all file names in the source directory\n",
    "    files = os.listdir(source_dir)\n",
    "\n",
    "    # Calculate the number of files for validation\n",
    "    validation_count = int(len(files) * validation_split)\n",
    "\n",
    "    # Randomly pick files for validation\n",
    "    validation_files = np.random.choice(files, validation_count, replace=False)\n",
    "\n",
    "    # Move files to the validation directory\n",
    "    for file_name in validation_files:\n",
    "        shutil.move(\n",
    "            os.path.join(source_dir, file_name),\n",
    "            os.path.join(validation_dir, label, file_name),\n",
    "        )\n",
    "\n",
    "print(\"Files successfully moved to the validation folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Set your dataset directory for the test set\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# The target number of files per class for the test set\n",
    "target_test_file_count = 250\n",
    "\n",
    "# For each class directory in the test dataset\n",
    "for class_dir in os.listdir(test_dir):\n",
    "    class_path = os.path.join(test_dir, class_dir)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        # Get all file names\n",
    "        files = os.listdir(class_path)\n",
    "\n",
    "        # If there are more than 250 files, we'll truncate the list\n",
    "        if len(files) > target_test_file_count:\n",
    "            # Randomly shuffle the list\n",
    "            random.shuffle(files)\n",
    "\n",
    "            # Select the files to remove\n",
    "            files_to_remove = files[target_test_file_count:]\n",
    "\n",
    "            # Remove the excess files\n",
    "            for f in files_to_remove:\n",
    "                os.remove(os.path.join(class_path, f))\n",
    "\n",
    "print(\"Test dataset truncation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
